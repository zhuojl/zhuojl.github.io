# 背景
在日常开发中，自己或者同事也遇到过不少系统异常，是很宝贵的经验，以后会统一记录维护下来

# JVM系列 

## 动态代理产生过多的类，而没有回收
### 现象
外部请求几乎全是超时，jvm一直进行老年代回收，却无法回收，系统不可用
### 原因分析
[原因分析](https://blog.csdn.net/zjl_csdn/article/details/88848051)
### 解决办法
升级jar包版本，回收动态代理类
### 延伸阅读
深入理解java虚拟机第二版

## full gc后，仍有较大内存没有被回收
### 现象
老年代频繁full gc，每5小时一次，而且每次回收后总有1g左右的内存无法回收，
配置：`-Xms2048m -Xmx4096m -XX:NewSize=512m -XX:MaxNewSize=512m` 
### 原因分析
当然，在发现问题就找运维要了dump，发现大量ThreadLocal中存有15M左右的日志数据，经过排查代码，发现是公司的日志
框架中，使用了ThreadLocal保存日志，使用完之后却没有remove，而是通过StringBuffer.setLength(0)来重置指针，
导致StringBuilder中字符数组的内存没有被清除，而由于使用线程池，所以内存一直无法释放。
### 解决办法
ThreadLocal.remove
### 延伸阅读
[ThreadLocal原理篇](https://www.jianshu.com/p/a1cd61fa22da)

## 承接上面一个问题，修改之后full gc还是比较频繁
### 现象
full gc 由原来的5个小时/次，变成了15小时每次
### 原因分析
正常情况，老年代内存的产生有几种情况：
1. 新生代GC后，超过eden存储大小的对象
2. 大对象直接进入老年代
3. 年龄到了设置值的对象
4. 动态年龄判断，提前晋升

在请求量没有太大变化的情况下，一般都是大对象，大接口的问题，导致较多对象一直无法释放，或者直接进入老年代。
上面还有一个现象是，跟其他服务对比，该服务年轻带gc很不频繁，感觉就像是上面说的第二点，大对象直接进入
老年代了，所以同事让运维申请了内存，整体扩充一倍，老年代gc给缓下来了，在不改代码的情况下，似乎也没什么
特别好的方式了。。当然这里也问过为什么不是只升级新生代，连坐老年代感觉收益不大，没有得到很好的答复，
后面再问下。

### 解决办法
升级内存，当然这方法指标不治本，根本方法是修改代码，快速释放内存，修改调用方式，将查询全部的接口改为分页查询等
### 延伸阅读
深入理解java虚拟机第二版

## 一次服务问题排查
### 现象
- 一个数据量很小的表的简单查询接口，耗时平均几百毫秒，波动大的时候，常常触发上层熔断。

~~ygc耗时很久，同个服务，各个节点之间存在 ygc耗时 差距大的问题~~

### 原因
- 没有使用链接池，每次请求都需要初始化链接和销毁链接，线程池设置不合理，每次初始化；
- 过程中，设置了autocommit=false，每次查询还需要执行一次commit，增加耗时

==============更新==============
ygc大的问题是因为jdk版本的问题，当前jdk版本25.181-b13，gc线程的数量根据宿主机的系统信息定的，所以gc线程数量很多，导致gc耗时特别久，  
可以调整参数：ParallelGCThreads=4， 或者升级jdk版本到openjdk:8u181。

gc线程多的问题一开始就注意到了，居然没想到可以设置回收线程数量来解决，diss一下自己。下次遇到类似问题，实在没思路就过下，[详细的文档](http://www.51gjie.com/java/551.html)

### 解决办法
- 使用 druid 链接池，配置springboot线程
- 取消 autocommit=false 设置


### 问题
- 接口耗时久的问题保持了好长一段时间，在公司出路链路追踪之后，才好好的进入排查，这点不是很好，早应该排查调用链路，核心组件等，  
再考虑压测模拟（TODO）。

- 通过扩容，和修改网关超时时间等保证了线上问题后，没有把优化排期。``执行力有待提高``


# 线程池系列

## 背景：
 某日线上某个定时任务没有执行，这个定时任务是在服务启动后放进线程池的，按理说肯定一开始就拿到线程并开始执行了，
 但是中途却突然停止了，当得知这个问题时，第二天同事让运维重启了服务，保证业务的正常运行（同当时自己的想法）
 但是真正的问题是什么呢，底层原因？
## 排查：
 1、通过日志平台，没有任务执行的日志，已经至少有3天没有跑定时任务了，并未发现什么原因
 2、查看监控平台，内存、请求量也没有异常
 3、在之前的工作中，发生过redis锁失效的问题，查看redis，没有发现异常，
 4、把情况跟其他同事沟通后，发现可能是线程池问题
 5、模拟复现，没发现问题，伪码如下：
 ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 2, KEEP_ALIVE_TIME, TimeUnit.SECONDS,
 new LinkedBlockingDeque<>(5), new ThreadPoolExecutor.CallerRunsPolicy())

 executor.execute(() -> {
    doSth1
    executor.execute(() -> doSth2);
 })
 且executor 仅用于这里。这样是不会发生死锁，只是任务多了就走reject逻辑，变成同步执行。
所以也可能是doSth2内部发生阻塞，导致任务不能继续执行，下次一定需要dump文件再重启



# 事务系列

## 使用spring事务隔离级别死锁
### 现象
大量报错，提示获取不到数据库链接
### 原因分析
两个事务，外部事务隔离级别为REQUIRED，内部事务REQUIRES_NEW，由于内部和外部，都更新同一条数据，导致死锁
### 解决办法
都用REQUIRED

# 其他
## iterator.hasNext 判断有值就continue
### 现象
集群中cpu使用率百分之一千，因为得不到时间，所以请求时间大量超时，线程得不到释放，所以又不听加线程
### 原因分析
这个是同事发现的问题，知道的时候已经有运维发现的线程dump了，线程状态RUNNABLE，运行到continue的位置，
那基本已经定位了。
### 解决办法
continue之前，先调用iterator.next();
### 延伸阅读
其实网上关于如何定位cpu占用率过高的帖子比较多，一年前遇到这个问题的时候还不知道怎么解决好，
[CPU占用过高分析](https://www.jianshu.com/p/3ba1e933682b)



