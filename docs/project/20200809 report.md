### 报表相关

目前所在项目组的主要一个职责就是做报表维护，各种各样的问题，这里做个简单记录

#### 职责问题，业务报表需要单独成立一个部门来维护吗？
我觉得不需要，应该由具体的业务方来提供需求（业务逻辑），交由大数据团队维护开发，或者大数据提供基础能力，由业务方维护。

#### 数据源乱的问题
单订单数据源就有很多种，mysql的主从，tiDb，mongo，drds，就一个接一个的换，维护不动了就换。。。。

其他业务相对还好，但是需要数据就开放 数据库 权限，需要就直链，苦不堪言。。。

#### 基础数据源质量差
报表最密切的订单数据，由于底层数据定义不一致，数据质量差，在报表系统的各个地方随处可见各种case when，逻辑复杂，维护艰难，

公司的另外一个报表组用kafka做了流计算，但是只是做了数据清洗，曾经一度觉得他们这样做没有意义，根本没有做计算，但其实是解决了原始数据质量差的问题，  
后续的维护和计算都可以在新的数据上进行，减少维护成本。

#### 组织架构的问题
公司做的是SaaS系统，但是却分了两个团队来做报表，底层的所有系统都没有这样分。

站在公司的角度上，我认为还是不该分成两个团队来做，也许可以从当初的团队中划分一个团队出来做，而不是从新成立一个团队，慢慢需求差异越来越大，
最终就是底层很多东西无法共享，维护成本越来越重，而研发等资源投入跟不上，因为领导可能觉得是copy过来的，对公司对团队来说都是不小的负担。

#### 团队空降、代码维护成本大
上面说到两个部门做报表，我所属的部门是后来成立的，当初从之前的部门借调过来的人走光，导致大面积没人熟悉产品，商户的问题穿透 运维、产品直
击研发到代码，产品也不作为，领导也不管，难受。

代码维护上，由于很多代码是几年前的代码，经过了无数人的蹂躏，维护难度大，但是大部分又不是很适合重构，重构的范围要求中有一条是：如果变更需求/变更很少（不到三次），
也能完成工作，就不需要重构。报表系统中的大部分问题，最终都是sql问题，少个条件啥的，排查时间还不少，就很难受。。。。当然这个问题在数据清洗之后还是能
得到一些解决。

#### 数据归档问题
大数据量下，新老数据需要做数据隔离，即归档，即便hbase这样的数据库能海量储存，不归档是不是也是一种浪费？最近又跑出一个数据源，没有做归档处理。
一般归档都是按时间归档，现在系统中有根据「另外的时间」查询的业务，导致查询归档数据时，不得不做特殊处理。
应该把「归档键」设置为一级条件，所有查询都需要带上。

#### 其他

##### flink 适用于报表吗
最近也看了些flink的资料，flink适用于三种场景，基于事件的业务处理、数据管道ETL、实时分析，监控；
而报表业务场景，基本是用不到flink才对，毕竟对实时要求就很低。

公司另外一个团队，之前根据kafka消费事件，做了一个数据清洗，他们把这称为``流计算``,但个人理解更多是ETL，解决原始数据质量差的问题。  
最近要搞实时计算，通过kafka消费事件自己来做，感觉就更离谱了。

前两天大数据同事给宣导flink（其实是blink）实时计算中提到，可以通过flink做实时计算给报表团队用。当然这其中可能还是会有一些问题，  
还需要和大数据团队再沟通交流。

###### blink数据重跑问题
- 只要数据源，通常是kafka，还在，就能重刷；blink可以通过指定事件时间进行重刷
- 如果要修某部分过久的数据，只能通过额外的程序修改。
- 对于老的存量数据，不能通过blink修，本来blink的定位就是实时计算工具，只计算，存储可以使用任何存储，所以老数据可以通过其他框架跑。

##### 存储
上面说到大数据团队提供blink，支持实时计算，但是他们却不提供「存储」，要业务方自己选择存储。。。但常见的存储不应该对他们来说很明显吗。。

TODO


